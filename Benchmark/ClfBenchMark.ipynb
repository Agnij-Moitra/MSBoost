{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman3, make_regression, make_friedman2, fetch_california_housing, load_diabetes, make_friedman1, make_sparse_uncorrelated, make_classification\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import log_loss, f1_score, auc, roc_auc_score, mean_squared_log_error\n",
    "import numpy as np\n",
    "import random\n",
    "import cython\n",
    "%load_ext Cython\n",
    "np.random.seed(7)\n",
    "random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "from MSBoost import MSBoostClassifier\n",
    "from sklearn.datasets import make_friedman3, make_regression, make_friedman2, fetch_california_housing, load_diabetes, make_friedman1, make_sparse_uncorrelated, make_classification\n",
    "cimport numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import log_loss, f1_score, auc, roc_auc_score, mean_squared_log_error\n",
    "\n",
    "def subsample(X, y, num_samples=1000, random_state=7):\n",
    "    \"\"\"\n",
    "    Subsample the arrays X and y.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Input array\n",
    "    - y: Target array\n",
    "    - num_samples: Number of samples to retain\n",
    "    - random_state: Seed for random number generator (default is None)\n",
    "\n",
    "    Returns:\n",
    "    - Subsampled X and y arrays\n",
    "    \"\"\"\n",
    "    if len(y) <= num_samples:\n",
    "        return X, y\n",
    "        \n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    indices = np.random.choice(len(y), num_samples, replace=False)\n",
    "\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "def get_card_split(df, cols, n=11):\n",
    "    \"\"\"\n",
    "    Splits categorical columns into 2 lists based on cardinality (i.e # of unique values)\n",
    "    Parameters (Source: https://github.com/shankarpandala/lazypredict/blob/dev/lazypredict/Supervised.py#L114)\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which the cardinality of the columns is calculated.\n",
    "    cols : list-like\n",
    "        Categorical columns to list\n",
    "    n : int, optional (default=11)\n",
    "        The value of 'n' will be used to split columns.\n",
    "    Returns\n",
    "    -------\n",
    "    card_low : list-like\n",
    "        Columns with cardinality < n\n",
    "    card_high : list-like\n",
    "        Columns with cardinality >= n\n",
    "        \n",
    "    \"\"\"\n",
    "    cond = df[cols].nunique() > n\n",
    "    card_high = cols[cond]\n",
    "    card_low = cols[~cond]\n",
    "    return card_low, card_high\n",
    "\n",
    "def append_row(df, data):\n",
    "    \"\"\"\n",
    "    Append a row of data to a DataFrame.\n",
    "\n",
    "    Parameters :\n",
    "        - df (pandas.DataFrame): The DataFrame to which the row will be appended.\n",
    "        - data (list): The data representing a row to be appended. Should be a list where each element corresponds to a column in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df.loc[len(df)] = data\n",
    "    \n",
    "import os\n",
    "import contextlib\n",
    "import sys\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            \n",
    "def score_clf(model, X, y):\n",
    "    return log_loss(y, model.predict_proba(X))\n",
    "\n",
    "def pre_process_y(y):\n",
    "    return LabelEncoder().fit_transform(y)\n",
    "\n",
    "def cv_evaluate(model, X, y, scoring=\"neg_mean_squared_error\", n_jobs=1):\n",
    "\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "    reg = model(n_estimators=100)\n",
    "    n_folds = 3\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=7)\n",
    "    with suppress_stdout():\n",
    "        cv_results = cross_val_score(reg, X, y, cv=kf, scoring=scoring, n_jobs=n_jobs)\n",
    "    mean_mse = np.mean(cv_results)\n",
    "    std_mse = np.std(cv_results)\n",
    "    sys.stdout = sys.__stdout__\n",
    "    sys.stderr = sys.__stderr__\n",
    "    return f\"{mean_mse:.4f} Â± {std_mse:.4f}\"\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=5, n_redundant=0, n_repeated=0, random_state=7)\n",
    "print(\"MSBoost Clf:\", cv_evaluate(MSBoostClassifier, X, y, score_clf))\n",
    "print(\"GBDT:\", cv_evaluate(GradientBoostingClassifier, X, y, score_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
